{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "\n",
    "from torchvision import transforms, utils, models\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import numpy as np\n",
    "from skimage import io, transform\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from torch.nn.functional import interpolate\n",
    "\n",
    "# import encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up hyperparameters and train settings\n",
    "IN_KERNEL = os.environ.get('KAGGLE_WORKING_DIR') is not None\n",
    "MIN_SAMPLES_PER_CLASS = 50\n",
    "BATCH_SIZE = 512\n",
    "LEARNING_RATE = 1e-3\n",
    "LR_STEP = 3\n",
    "LR_FACTOR = 0.5\n",
    "# NUM_WORKERS = multiprocessing.cpu_count()\n",
    "MAX_STEPS_PER_EPOCH = 15000\n",
    "NUM_EPOCHS = 2 ** 32\n",
    "LOG_FREQ = 500\n",
    "NUM_TOP_PREDICTS = 20\n",
    "TIME_LIMIT = 9 * 60 * 60\n",
    "\n",
    "dtype = torch.cuda.FloatTensor\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([3, 224, 224]) tensor(142820)\n",
      "1\n",
      "torch.Size([3, 224, 224]) tensor(104169)\n",
      "2\n",
      "torch.Size([3, 224, 224]) tensor(37914)\n",
      "3\n",
      "torch.Size([3, 224, 224]) tensor(102140)\n"
     ]
    }
   ],
   "source": [
    "# Loading Train Dataset\n",
    "\n",
    "class LandmarksDataset(Dataset):\n",
    "    \"\"\"Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 0]) #INCORRECT, NEEDS TO FIT TRAIN FOLDER NAMING\n",
    "        img_name += '.jpg'\n",
    "        try:\n",
    "            image = io.imread(img_name)\n",
    "        except:\n",
    "            return None\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 2]\n",
    "        sample = {'image': image, 'class': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['class']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'landmarks': torch.from_numpy(np.array(landmarks))}\n",
    "    \n",
    "\n",
    "landmarks_dataset = LandmarksDataset(csv_file = 'train.csv',\n",
    "                                     root_dir = 'train/',\n",
    "                                     transform = ToTensor()\n",
    "                                     )\n",
    "\n",
    "#Confirm shapes and labels are of correct form\n",
    "for i in range(len(landmarks_dataset)):\n",
    "    print(i)\n",
    "    sample = landmarks_dataset[i]\n",
    "    if sample:\n",
    "        print(sample['image'].size(), sample['landmarks'])\n",
    "\n",
    "    if i == 3:\n",
    "        break\n",
    "        \n",
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset. \n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start=0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "        \n",
    "dataloaders = DataLoader(landmarks_dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pre-trained FCN ResNet-50 model\n",
    "\n",
    "#FCN_model = models.segmentation.fcn_resnet50(pretrained=True, \n",
    "#                                             progress=True, \n",
    "#                                             num_classes=200000)\n",
    "\n",
    "# FCN_model = encoding.models.get_model('FCN_ResNet50_ADE', pretrained=True)\n",
    "\n",
    "resnet_50 = models.segmentation.resnet50(pretrained=True,\n",
    "                                         progress=True,\n",
    "                                         num_classes=200000)\n",
    "\n",
    "# print(list(FCN_model.children()))\n",
    "\n",
    "# print(len(list(list(FCN_model.children())[0])))\n",
    "\n",
    "for param in FCN_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "FCN_model.fc = nn.Linear(1024, 2)\n",
    "\n",
    "#FCN_model = FCN_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_FCN = optim.SGD(FCN_model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_FCN, step_size=7, gamma=0.1)\n",
    "\n",
    "# print(newmodel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN_model = train_model(FCN_model, criterion, optimizer_FCN, exp_lr_scheduler,\n",
    "#                        num_epochs=20)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "    \n",
    "\n",
    "#https://github.com/nashory/DeLF-pytorch/blob/master/train/layers.py\n",
    "    \n",
    "class WeightedSum2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WeightedSum2d, self).__init__()\n",
    "    def forward(self, x):\n",
    "        x, weights = x\n",
    "        assert x.size(2) == weights.size(2) and x.size(3) == weights.size(3),\\\n",
    "                'err: h, w of tensors x({}) and weights({}) must be the same.'\\\n",
    "                .format(x.size, weights.size)\n",
    "        y = x * weights                                       # element-wise multiplication\n",
    "        y = y.view(-1, x.size(1), x.size(2) * x.size(3))      # b x c x hw\n",
    "        return torch.sum(y, dim=2).view(-1, x.size(1), 1, 1)  # b x c x 1 x 1\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__\n",
    "\n",
    "\n",
    "class SpatialAttention2d(nn.Module):\n",
    "    '''\n",
    "    SpatialAttention2d\n",
    "    2-layer 1x1 conv network with softplus activation.\n",
    "    <!!!> attention score normalization will be added for experiment.\n",
    "    '''\n",
    "    def __init__(self, in_c, act_fn='relu'):\n",
    "        super(SpatialAttention2d, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_c, 512, 1, 1)                 # 1x1 conv\n",
    "        if act_fn.lower() in ['relu']:\n",
    "            self.act1 = nn.ReLU()\n",
    "        elif act_fn.lower() in ['leakyrelu', 'leaky', 'leaky_relu']:\n",
    "            self.act1 = nn.LeakyReLU()\n",
    "        self.conv2 = nn.Conv2d(512, 1, 1, 1)                    # 1x1 conv\n",
    "        self.softplus = nn.Softplus(beta=1, threshold=20)       # use default setting.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x : spatial feature map. (b x c x w x h)\n",
    "        s : softplus attention score \n",
    "        '''\n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.softplus(x)\n",
    "        return x\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__\n",
    "\n",
    "        \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, in_c, act_fn='relu'):\n",
    "        super(Attention, self).__init__()\n",
    "        self.SpatialAttention = nn.SpacialAttention2d(in_c)\n",
    "        self.WeightedSum = nn.WeightedSum2d()\n",
    "    def forward(self, x):\n",
    "        weights = self.SpatialAttention(x)\n",
    "        a = F.normalize(x, p=2, dim=1)\n",
    "        return self.WeightedSum2d((a, weights))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=1, kernel_size=5, stride=1, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.Attention(),\n",
    "    Flatten(),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "a = torch.Tensor(range(224))\n",
    "model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
